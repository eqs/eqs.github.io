<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Satoshi Murashige</title>
    <link>https://eqs.github.io/</link>
    <description>Recent content on Satoshi Murashige</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Mar 2018 14:44:21 +0900</lastBuildDate>
    
	<atom:link href="https://eqs.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Processingとフラグメントシェーダで画像処理を書いてみた</title>
      <link>https://eqs.github.io/post/glsl-image-processing/</link>
      <pubDate>Wed, 21 Mar 2018 14:44:21 +0900</pubDate>
      
      <guid>https://eqs.github.io/post/glsl-image-processing/</guid>
      <description>&lt;p&gt;フラグメントシェーダとは，CGの描画パイプラインにおいて，
ベクタ表現からラスタ表現に変換された画像の各ピクセルに対する処理を行うプログラムであり，3DCGの陰影表現などに用いられる．
本記事では，OpenGL用のシェーダ記述言語であるGLSL (openGL Shading Language) を用いて記述した画像処理の例とその実行結果を紹介する．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Open Sound ControlでPythonとProcessing間の連携をやってみた</title>
      <link>https://eqs.github.io/post/python-osc/</link>
      <pubDate>Sun, 28 Jan 2018 15:41:50 +0900</pubDate>
      
      <guid>https://eqs.github.io/post/python-osc/</guid>
      <description>&lt;p&gt;メディアアート開発の際，
OpenCV for Pythonを用いた画像解析で映像から情報を抽出し，
Processingで作った映像にその情報を反映したいというようなシチュエーションがある．
OpenCVならProcessingにもライブラリはあるが，
画像解析に関する試行錯誤はJupyter NotebookやSpyder IDEのあるPythonの方がやりやすい．
そこで，PythonとProcessingの両方の良いところを活かすために
Open Sound Control (OSC) による両者の連携を実装してみる．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>このブログについて</title>
      <link>https://eqs.github.io/post/first-post/</link>
      <pubDate>Sun, 21 Jan 2018 00:30:56 +0900</pubDate>
      
      <guid>https://eqs.github.io/post/first-post/</guid>
      <description>このブログでは開発で得た知識や技術に関するメモを書いていきます．</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://eqs.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eqs.github.io/about/</guid>
      <description>I am a master cource student at the Mathematical Informatics Laboratory, in Nara Institute of Science and Technology a.k.a. NAIST.
Research Interest Computer Vision methods for automatic measurement and quantification of animals behavior
Skill  Programming languages  Python (Numpy, PyTorch, Keras, OpenCV, scikit-learn, Flask) Julia MATLAB JavaScript (Vue.js, p5.js) Java (Processing) C# (Unity) C++ (openFrameworks) GLSL CUDA C  Tools  Git Docker DeepLabCut   Education  2011.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://eqs.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eqs.github.io/contact/</guid>
      <description>murashige.satoshi＊is.naist.jp (＊→@)
(NAISTの受験に関する相談は大学または研究室の方へお願いします)</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://eqs.github.io/publication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://eqs.github.io/publication/</guid>
      <description>Satoshi Murashige, Noriaki Suetake, and Takanori Koga, ``Hand Gesture Recognition and Tracking for IR Image Using Random Forest and Median Flow,&amp;rdquo; Proc. of 2018 International Workshop on Smart Info-Media Systems in Asia (SISA 2018), pp.34-39, Kanagawa, Japan, Dec. 13-14, 2018. Murashige, S., Kubo, T., Ouchi, R., Nakahara, E., Kikusui, T. &amp;amp; Ikeda, K., Tracking of Body Parts of the Dog using DeepLabCut. 日本動物心理学会第78回大会, 広島, 2018年8月. (oral) 村重哲史, 古賀崇了, &amp;ldquo;Random ForestとMedian Flowを用いたハンドジェスチャの認識と追跡に関する検討,&amp;rdquo; 信学技報, Vol.</description>
    </item>
    
  </channel>
</rss>